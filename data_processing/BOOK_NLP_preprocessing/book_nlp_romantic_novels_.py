# -*- coding: utf-8 -*-
"""book_NLP_romantic_novels_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LOx5vjyuFWYEJcicuO25lP1b_EVHiI7j
"""

! pip install booknlp

! python -m spacy download en_core_web_sm

import spacy
from booknlp.booknlp import BookNLP
import time
from pathlib import Path
import os

nlp = spacy.load('en_core_web_sm')

# mount Google Drive to the '/content/drive' directory in the Colab environment

from google.colab import drive
drive.mount('/content/drive')

model_params={
                "pipeline":"entity,quote,supersense,event,coref",
                "model":"small"

                }

booknlp=BookNLP("en", model_params)

# SIC! Use this code for processing books splitted by chapters, if you want to keep everything in place!

output_directory_base = '/content/drive/MyDrive/novels_splitted_to_bookNLP/processed_novels'

rootdir = "/content/drive/MyDrive/novels_splitted_to_bookNLP"

def process_all_texts(rootdir):
    for path in Path(rootdir).iterdir():  # iterate through all subdirs and files in rootdir
        if path.is_dir():  # if the path is a directory
            process_all_texts(path)  # recursively call this function on the subdirectory
        if path.is_file():  # if the path is a file
            book_id = Path(path).stem  # .stem returns the last element of the path, which in our case is the book name
            # split the root directory path to get the base directory and the specific subdirectory
            base_dir, specific_dir = os.path.split(rootdir)
            # create the base output directory (specific to each book), e.g., 'Bowen_Brooklynaire_splitted_booknlp_output'
            output_directory_base = os.path.join(base_dir, f"{specific_dir}_booknlp_output")
            os.makedirs(output_directory_base, exist_ok=True)  # create the directory if it doesn't exist
            # create the specific output directory for each file, e.g., '{book_id}_booknlp_output'
            output_directory = os.path.join(output_directory_base, f"{book_id}_booknlp_output")
            os.makedirs(output_directory, exist_ok=True)  # create the directory if it doesn't exist
            booknlp.process(path, output_directory, book_id)  # process the book with booknlp
            print(f"Preprocessing book {Path(path).stem}")  # print the name of the preprocessed book

process_all_texts(root)

# SIC! Use this code ONLY for 'all_romantic_novels_full' or your outputfiles will be stored in the wrong way!

output_directory_base = '/content/drive/MyDrive/toy_dataset/all_romantic_novels_full/all_romantic_novels_full_with_names/processed_novels'
root = "/content/drive/MyDrive/toy_dataset/all_romantic_novels_full/all_romantic_novels_full_with_names"

def process_all_texts(rootdir):
    for path in Path(rootdir).iterdir():  # iterate though all subdirs in rootdir
        if path.is_dir():
            process_all_texts(path)  # call this function on the subdir
        if path.is_file():
            book_id = Path(path).stem  # .stem returns the last element of the path, which in our case is the book name
            output_directory = os.path.join(output_directory_base, f"{book_id}_booknlp_output")
            os.makedirs(output_directory, exist_ok=True)  # Create the directory, don't raise error if it already exists
            booknlp.process(path, output_directory, book_id)
            print(f"Preprocessing book {Path(path).stem}")

process_all_texts(root)